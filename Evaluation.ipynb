# Enable MPS fallback for CTCLoss
import os
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

import json
from pathlib import Path
import glob
from typing import Dict, List, Tuple

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split, Subset
from PIL import Image
import torchvision.transforms as transforms
import pandas as pd

import config
from crnn import build_crnn  # your CRNN definition

def load_labels_from_csv(csv_path: Path) -> Dict[str, str]:
    df = pd.read_csv(csv_path)
    # expects columns: filename, label
    return dict(zip(df["filename"], df["label"]))


def encode_label(text: str) -> List[int]:
    """
    Encode text into a list of indices using config.CHAR_TO_IDX.
    Unknown characters are skipped.
    """
    indices = []
    for ch in text:
        if ch in config.CHAR_TO_IDX:
            indices.append(config.CHAR_TO_IDX[ch])
        else:
            # skip char if not in vocabulary
            pass
    return indices


class WordImageDataset(Dataset):
    def __init__(self, images_dir: Path, label_dict: Dict[str, str]):
        super().__init__()
        self.images_dir = Path(images_dir)
        self.image_paths = sorted(glob.glob(str(self.images_dir / "*.png")))
        self.label_dict = label_dict

        self.transform = transforms.Compose([
            transforms.Resize((config.IMG_HEIGHT, config.IMG_WIDTH)),
            transforms.ToTensor(),  # [1, H, W] since we convert to "L"
        ])

    def __len__(self) -> int:
        return len(self.image_paths)

    def __getitem__(self, idx: int):
        img_path = Path(self.image_paths[idx])
        img = Image.open(img_path).convert("L")  # grayscale

        img_tensor = self.transform(img)  # [1, H, W]

        filename = img_path.name
        if filename not in self.label_dict:
            raise KeyError(f"No label found for image {filename}")

        text_label = self.label_dict[filename]
        label_indices = encode_label(text_label)
        label_tensor = torch.tensor(label_indices, dtype=torch.long)

        return img_tensor, label_tensor, text_label, str(img_path)
